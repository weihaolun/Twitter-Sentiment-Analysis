{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5048c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chelseafusco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import twitter_samples   \n",
    "import matplotlib.pyplot as plt           \n",
    "import random  \n",
    "nltk.download('stopwords')\n",
    "import re                                  \n",
    "import string                             \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0316c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each file as data frames.\n",
    "positive_df = pd.read_csv(\"resources/dw_pos.csv\", index_col=[0])\n",
    "negative_df = pd.read_csv(\"resources/dw_neg.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8fa555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956967789</th>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956971170</th>\n",
       "      <td>@annarosekerr agreed</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956972097</th>\n",
       "      <td>Wondering why I'm awake at 7am,writing a new s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956977084</th>\n",
       "      <td>mmm much better day... so far! it's still quit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956977187</th>\n",
       "      <td>@DavidArchie &amp;lt;3 your gonna be the first  tw...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content  target\n",
       "tweet_id                                                             \n",
       "1956967789               wants to hang out with friends SOON!     1.0\n",
       "1956971170                               @annarosekerr agreed     1.0\n",
       "1956972097  Wondering why I'm awake at 7am,writing a new s...     1.0\n",
       "1956977084  mmm much better day... so far! it's still quit...     1.0\n",
       "1956977187  @DavidArchie &lt;3 your gonna be the first  tw...     1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebebaf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  13112\n",
      "Number of negative tweets:  13913\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "\n",
      "The type of all_negative_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n",
      "The type of a tweet entry is:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "all_positive_tweets = positive_df[\"content\"].tolist()\n",
    "all_negative_tweets = negative_df[\"content\"].tolist()\n",
    "\n",
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('\\nThe type of all_negative_tweets is: ', type(all_negative_tweets))\n",
    "\n",
    "\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))\n",
    "print('The type of a tweet entry is: ', type(all_positive_tweets[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297cfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_positive_words = []\n",
    "# for sentence in all_positive_tweets:\n",
    "#     total_positive_words.append(sentence.count(' '))\n",
    "    \n",
    "# total_negative_words = []\n",
    "# for sentence in all_negative_tweets:\n",
    "#     total_negative_words.append(sentence.count(' '))\n",
    "  \n",
    "# import plotly.graph_objects as go\n",
    "# import numpy as np\n",
    "\n",
    "# x0 = np.array(total_positive_words)\n",
    "# x1 = np.array(total_negative_words)\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x=x1, name = 'Negative'))\n",
    "# fig.add_trace(go.Histogram(x=x0, name = 'Positive'))\n",
    "\n",
    "# # Overlay both histograms\n",
    "# fig.update_layout(barmode='overlay')\n",
    "# # Reduce opacity to see both histograms\n",
    "# fig.update_traces(opacity=0.75)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b50ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets_func(tweets_stem): \n",
    "\n",
    "    #Remove Retweets\n",
    "    def remove_RT(all_positive_tweets):\n",
    "        return re.sub(r'^RT[\\s]+', '', str(tweet))\n",
    "\n",
    "    removed_RT = []\n",
    "    for tweet in all_positive_tweets:\n",
    "        x = remove_RT(tweet)\n",
    "        removed_RT.append(x)\n",
    "\n",
    "    #Remove Hyperlinks\n",
    "    def remove_HL(removed_RT):\n",
    "        return re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', str(tweet))\n",
    "\n",
    "    removed_HL = []\n",
    "    for tweet in removed_RT:\n",
    "        x = remove_HL(tweet)\n",
    "        removed_HL.append(x)\n",
    "\n",
    "    #Remove Hashtags\n",
    "    def remove_Hash(removed_HL):\n",
    "        return re.sub(r'#', '', str(tweet))\n",
    "    \n",
    "    removed_Hash = []\n",
    "    for tweet in removed_HL:\n",
    "        x = remove_Hash(tweet)\n",
    "        removed_Hash.append(x)\n",
    "\n",
    "    #Remove Numbers \n",
    "    def remove_Numbers(removed_Hash):\n",
    "        return re.sub(r'[0-9]', '', str(tweet))\n",
    "\n",
    "    removed_Numbers = []\n",
    "    for tweet in removed_Hash:\n",
    "        x = remove_Numbers(tweet)\n",
    "        removed_Numbers.append(x)\n",
    "\n",
    "    #Remove Emojis \n",
    "    def remove_Emojis(removed_Numbers):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', str(tweet))\n",
    "\n",
    "    removed_Emojis = []\n",
    "    for tweet in removed_Numbers:\n",
    "        x = remove_Emojis(tweet)\n",
    "        removed_Emojis.append(x)\n",
    "\n",
    "    #Remove Mentions \n",
    "    def remove_Mentions(removed_Emojis):\n",
    "        return re.sub(\"@[A-Za-z0-9_]+\",\"\", str(tweet))\n",
    "\n",
    "    removed_Mentions = []\n",
    "    for tweet in removed_Emojis:\n",
    "        x = remove_Mentions(tweet)\n",
    "        removed_Mentions.append(x)\n",
    "\n",
    "    #Store finished product from above extractions in tweet2\n",
    "    tweet2 = removed_Mentions\n",
    "\n",
    "    #Tokenizer\n",
    "    def Tokenizer(tweet2):\n",
    "        # instantiate the tokenizer class\n",
    "        tokenizer = TweetTokenizer(preserve_case=False, \n",
    "                               strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "        return tokenizer.tokenize(tweet)\n",
    "\n",
    "    Tokenized = []\n",
    "    for tweet in tweet2:\n",
    "        x = Tokenizer(tweet)\n",
    "        Tokenized.append(x)\n",
    "\n",
    "    #Import the english stop words list from NLTK\n",
    "    stopwords_english = stopwords.words('english') \n",
    "\n",
    "    #Removing stop-words and punctuation (we may want to customize the stop-word list and/or the punctuation )\n",
    "    tweets_clean = []\n",
    "    for i in range(len(Tokenized)):\n",
    "        row = []\n",
    "        for element in Tokenized[i]: #Go through every individual word\n",
    "            if (element not in stopwords_english and  # remove stopwords\n",
    "            element not in string.punctuation): # remove punctuation\n",
    "                row.append(element)\n",
    "        tweets_clean.append(row)\n",
    "        i+=1\n",
    "\n",
    "    #Stemming \n",
    "    # Instantiate stemming class\n",
    "    stemmer = PorterStemmer() \n",
    "    # Create an empty list to store the stems\n",
    "    tweets_stem = [] \n",
    "    for i in range(len(tweets_clean)):\n",
    "        row =[]\n",
    "        for word in tweets_clean[i]:\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            row.append(stem_word)  # append to the list\n",
    "        tweets_stem.append(row)\n",
    "        i+=1\n",
    "\n",
    "    return(tweets_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdbd6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_df():\n",
    "    test_pos_tweets = clean_tweets_func(all_positive_tweets)\n",
    "    test_neg_tweets = clean_tweets_func(all_negative_tweets)\n",
    "    \n",
    "    pos_df = pd.DataFrame({\"tweet\":test_pos_tweets})\n",
    "    for length in range(len(pos_df)):\n",
    "        pos_df[\"score\"] = 1.0\n",
    "    \n",
    "    neg_df = pd.DataFrame({\"tweet\":test_neg_tweets})\n",
    "    for length in range(len(neg_df)):\n",
    "        neg_df[\"score\"] = 0.0\n",
    "        \n",
    "        \n",
    "    combined_df = pd.concat([pos_df,neg_df])\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca7129d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a19243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_combined_df = combined_df.reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc8234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[want, hang, friend, soon]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[agre]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wonder, i'm, awak, write, new, song, plot, ev...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mmm, much, better, day, ..., far, still, quit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gonna, first, twitter, ;), caus, amaz, lol, c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  score\n",
       "0                         [want, hang, friend, soon]    1.0\n",
       "1                                             [agre]    1.0\n",
       "2  [wonder, i'm, awak, write, new, song, plot, ev...    1.0\n",
       "3  [mmm, much, better, day, ..., far, still, quit...    1.0\n",
       "4  [gonna, first, twitter, ;), caus, amaz, lol, c...    1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f9b0dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26219</th>\n",
       "      <td>[succes, follow, tayla]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26220</th>\n",
       "      <td>[happi, mother, day, love]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26221</th>\n",
       "      <td>[happi, mother', day, mommi, woman, man, long,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26222</th>\n",
       "      <td>[wassup, beauti, follow, peep, new, hit, singl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26223</th>\n",
       "      <td>[bullet, train, tokyo, gf, visit, japan, sinc,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  score\n",
       "26219                            [succes, follow, tayla]    0.0\n",
       "26220                         [happi, mother, day, love]    0.0\n",
       "26221  [happi, mother', day, mommi, woman, man, long,...    0.0\n",
       "26222  [wassup, beauti, follow, peep, new, hit, singl...    0.0\n",
       "26223  [bullet, train, tokyo, gf, visit, japan, sinc,...    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_combined_df['score'] = dw_combined_df['score'].replace(np.nan, 0)\n",
    "dw_combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dae95133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_combined_df.to_csv('Resources/DW_CleanedSentiments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab7eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
